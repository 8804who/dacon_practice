{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 512\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/test.csv')\n",
    "test_df = test_df.drop('pair_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_annotation(x):\n",
    "    x = x+'\\n'\n",
    "    x = re.sub(r'\\n.*\\\\\\n','\\n',x)\n",
    "    x = re.sub(r'//.*\\n','\\n',x)\n",
    "    x = re.sub(r'/\\*.*\\*/','',x)\n",
    "    x = re.sub(r'#if 0.*#endif','',x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(x):\n",
    "    x = re.sub(r'https*\\S+', ' ', x) # remove links\n",
    "    x = re.sub(r'http*\\S+', ' ', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_sign(x):\n",
    "    x = re.sub(r' +', ' ', x)\n",
    "    x = re.sub(r' \\+ | \\+|\\+ ','+',x)\n",
    "    x = re.sub(r' - | -|- ','-',x)\n",
    "    x = re.sub(r' \\* | \\*|\\* ','*',x)\n",
    "    x = re.sub(r' / | /|/ ','/',x)\n",
    "    x = re.sub(r' % | %|% ','%',x)\n",
    "    x = re.sub(r' = | =|= ','=',x)\n",
    "    x = re.sub(r' > | >|> ','>',x)\n",
    "    x = re.sub(r' < | <|< ','=',x)\n",
    "    x = re.sub(r' !','!',x)\n",
    "    x = re.sub(r' & | &|& ','&',x)\n",
    "    x = re.sub(r' \\| | \\||\\| ', '|', x)\n",
    "    x = re.sub(r' : | :|: ',':',x)\n",
    "    x = re.sub(r' \\? | \\?|\\? ','?',x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_std(x):\n",
    "    x = re.sub(r'std::','',x)\n",
    "    x = re.sub(r'using namespace std;','',x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_include(x):\n",
    "    x = re.sub(r'#include.*>','',x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(x):\n",
    "    x = x.lower() # lowercase everything\n",
    "    x = x.encode('ascii', 'ignore').decode()  # remove unicode characters\n",
    "    x = remove_std(x)\n",
    "    x = remove_links(x)\n",
    "    x = remove_include(x)\n",
    "    x = remove_annotation(x)\n",
    "    x = standardize_sign(x)\n",
    "    x = re.sub(r'\\n', ' ', x)\n",
    "    x = re.sub(r'\\t', ' ', x)\n",
    "    x = re.sub(r' +', ' ', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "tokenizer.truncation_side = 'left'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/graphcodebert-base\", num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        code1, code2 = self.df.iloc[idx]\n",
    "        code1 = text_clean(code1)\n",
    "        code2 = text_clean(code2)\n",
    "        return code1, code2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Datasets(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, model_name):\n",
    "    preds = np.array([])\n",
    "    probs = np.array([[1,1]])\n",
    "    for code1, code2 in tqdm(test_loader):\n",
    "        encoded_list = []\n",
    "        attention_mask_list = []\n",
    "\n",
    "        for c1, c2 in zip(code1, code2):\n",
    "            tokenized = tokenizer(c1, c2, max_length=MAX_LEN, padding='max_length', truncation=True)\n",
    "            encoded_list.append(tokenized['input_ids'])\n",
    "            attention_mask_list.append(tokenized['attention_mask'])\n",
    "\n",
    "        input_ids = torch.tensor(encoded_list)\n",
    "        input_mask = torch.tensor(attention_mask_list)\n",
    "        input_ids, input_mask = input_ids.to(device), input_mask.to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            outputs = model(input_ids, attention_mask=input_mask)\n",
    "        logits = outputs['logits']\n",
    "        logits = logits.detach().cpu()\n",
    "        prob = F.softmax(logits)\n",
    "        pred = np.argmax(prob,axis=1)\n",
    "        probs = np.append(probs, prob, axis=0)\n",
    "        preds = np.append(preds, pred)\n",
    "    submission = pd.read_csv('./data/sample_submission.csv')\n",
    "    submission['similar'] = preds\n",
    "    submission.to_csv('./submission/{model_name}.csv'.format(model_name=model_name), index=False)\n",
    "    submission['probs_0'] = probs[1:,0]\n",
    "    submission['probs_1'] = probs[1:,1]\n",
    "    submission.to_csv('./probs/{model_name}.csv'.format(model_name=model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point = torch.load(f'./savepoint/{model_name}.pt')\n",
    "model.load_state_dict(check_point['State_dict'])\n",
    "inference(model, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
