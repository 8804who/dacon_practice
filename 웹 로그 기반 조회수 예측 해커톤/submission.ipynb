{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBLjhFF5vgRe"
      },
      "outputs": [],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "koo34kNpvgRg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "seed=42\n",
        "seed_everything(seed) # Seed 고정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Bwytg4gvvgRh"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리(공통)\n",
        "모델 학습을 위해 데이터 전처리를 수행하는 과정입니다. 결측값들을 'NAN' 값으로 채워주고 **bounced** 변수의 값을 문자형으로 치환해 주었습니다. 또한 학습 과정에서 **bounced** 변수의 값이 **not_bounced**인 데이터들만 사용하도록 데이터를 걸러내는 작업을 했습니다."
      ],
      "metadata": {
        "id": "xCeBw3HB4lxH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4mCTDDTMvgRi"
      },
      "outputs": [],
      "source": [
        "train.fillna('NAN', inplace=True)\n",
        "test.fillna('NAN', inplace=True)\n",
        "\n",
        "train['bounced']=train['bounced'].replace({0:'not_bounced',1:'bounced'})\n",
        "test['bounced']=test['bounced'].replace({0:'not_bounced',1:'bounced'})\n",
        "\n",
        "train = train[train['bounced'] == 'not_bounced']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "본격적인 데이터 전처리 과정에 앞서 **sessionID**와 **userID** 컬럼을 제거하였고 앙상블에 활용한 2가지 모델의 데이터 전처리 과정에 차이가 있기 때문에 똑같은 데이터셋을 각각 두 개씩 생성하였습니다."
      ],
      "metadata": {
        "id": "rbjPzP805CEZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aNvnlcvLvgRi"
      },
      "outputs": [],
      "source": [
        "drop_table = ['sessionID','userID']\n",
        "train1 = train.drop(drop_table,axis=1)\n",
        "train2 = train.drop(drop_table,axis=1)\n",
        "test1 = test.drop(drop_table,axis=1)\n",
        "test2 = test.drop(drop_table,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리(모델1)\n",
        "첫 번째 모델은 **transaction_revenue** 변수는 제거하고 남은 수치형 변수들에는 MinMaxScaling을 적용하였습니다."
      ],
      "metadata": {
        "id": "qwgFU-tT5YGF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zVT3jN69vgRi"
      },
      "outputs": [],
      "source": [
        "train1 = train1.drop('transaction_revenue', axis=1)\n",
        "test1 = test1.drop('transaction_revenue', axis=1)\n",
        "\n",
        "features = ['quality','duration','transaction']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train1[features] = scaler.fit_transform(train1[features])\n",
        "test1[features] = scaler.transform(test1[features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XfrPdWFAvgRi"
      },
      "outputs": [],
      "source": [
        "categorical_features = [\n",
        "    \"browser\",\n",
        "    \"OS\",\n",
        "    \"device\",\n",
        "    \"continent\",\n",
        "    \"subcontinent\",\n",
        "    \"country\",\n",
        "    \"traffic_source\",\n",
        "    \"traffic_medium\",\n",
        "    \"keyword\",\n",
        "    \"referral_path\",\n",
        "]\n",
        "for i in categorical_features:\n",
        "    train1[i] = train1[i].astype('category')\n",
        "    test1[i] = test1[i].astype('category')\n",
        "\n",
        "train1_X = train1.drop(['TARGET','bounced'], axis=1)\n",
        "train1_y = train1['TARGET']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습 및 예측(모델1)\n",
        "모델은 CatBoostRegressor를 사용하였고 KFold 방식(k=5)을 적용하였습니다.\n",
        "예측값은 각각의 모델에서 예측값을 출력하고 평균을 낸 값을 최종 예측값으로 사용하였습니다."
      ],
      "metadata": {
        "id": "hF33wj2y5owD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JxjzHBpfvgRj"
      },
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=5)\n",
        "models = []\n",
        "for train_index, test_index in kf.split(train1_X):\n",
        "    models.append(CatBoostRegressor(random_state=seed, verbose=False))\n",
        "    kfold_train_X, kfold_train_y = train1_X.iloc[train_index], train1_y.iloc[train_index]\n",
        "    kfold_test_X,  kfold_test_y  = train1_X.iloc[test_index],  train1_y.iloc[test_index]\n",
        "    train_pool = Pool(data=kfold_train_X, label=kfold_train_y, cat_features=categorical_features)\n",
        "    models[-1].fit(train_pool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9eaBWuIkvgRj"
      },
      "outputs": [],
      "source": [
        "test_pool = Pool(data=test1.drop('bounced', axis=1), cat_features=categorical_features)\n",
        "pred1 = np.array([models[0].predict(test_pool)])\n",
        "for i in range(1, 5):\n",
        "  pred1 = np.append(pred1, np.array([models[i].predict(test_pool)]),axis=0)\n",
        "pred1 = np.mean(pred1, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 예측값 후처리\n",
        "모델에서 예측한 값들을 후처리하는 과정입니다.\n",
        "Train 데이터를 살펴본 결과 Target 값은 1보다 크거나 같은 값만 존재한다고 판단하여 예측값이 1보다 작은 경우 1로 만들어주었습니다.\n",
        "또한 Train 데이터에서 **bounced** 변수가 1인 경우 $($저는 0을 **not_bounced**로 1을 **bounced**로 치환했습니다.$)$ Target 값이 무조건 1로 고정되어 있었던 것을 보고 **bounced**가 1일 경우 예측값을 1로 후처리를 해주었습니다."
      ],
      "metadata": {
        "id": "49mXXeHE4fXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred1 = [1 if i < 1 else i for i in pred1]\n",
        "for i, bounced in enumerate(test.bounced):\n",
        "  if bounced == 'bounced':\n",
        "    pred1[i] = 1"
      ],
      "metadata": {
        "id": "KgptA6Lp0W6j"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 전처리(모델2)\n",
        "\n",
        "두 번째 모델은 **quality**, **duration** 변수들에 로그 변환을 적용한 후 모든 수치형 변수에 MinMaxScaling을 적용하였습니다. 추가로 **Target** 값에도 로그 변환을 적용하였습니다.\n"
      ],
      "metadata": {
        "id": "eEpUElZe6CX0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wcBMD015vgRk"
      },
      "outputs": [],
      "source": [
        "def log_transformation(data):\n",
        "    features = ['quality','duration']\n",
        "    for feature in features:\n",
        "        data[feature] = np.log1p(data[feature])\n",
        "    if 'TARGET' in data.columns:\n",
        "        data['TARGET'] = np.log1p(data['TARGET'])\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "t6R0jVX6vgRl"
      },
      "outputs": [],
      "source": [
        "train2 = log_transformation(train2)\n",
        "test2 = log_transformation(test2)\n",
        "\n",
        "features = ['quality','duration','transaction','transaction_revenue']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train2[features] = scaler.fit_transform(train2[features])\n",
        "test2[features] = scaler.transform(test2[features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3VHm2NOxvgRl"
      },
      "outputs": [],
      "source": [
        "categorical_features = [\n",
        "    \"browser\",\n",
        "    \"OS\",\n",
        "    \"device\",\n",
        "    \"continent\",\n",
        "    \"subcontinent\",\n",
        "    \"country\",\n",
        "    \"traffic_source\",\n",
        "    \"traffic_medium\",\n",
        "    \"keyword\",\n",
        "    \"referral_path\",\n",
        "]\n",
        "for i in categorical_features:\n",
        "    train2[i] = train2[i].astype('category')\n",
        "    test2[i] = test2[i].astype('category')\n",
        "\n",
        "train2_X = train2.drop(['TARGET','bounced'], axis=1)\n",
        "train2_y = train2['TARGET']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습 및 예측(모델2)\n",
        "모델 1과 같이 CatBoostRegressor와 KFold 방식을 사용하였습니다. 예측값은 각각의 모델에서 예측값에 역로그 변환을 적용한 후 그 값들의 평균을 최종 예측값으로 사용하였습니다."
      ],
      "metadata": {
        "id": "_oTtJYZB6d_I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "KSjZo1ytvgRl"
      },
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=5)\n",
        "models = []\n",
        "for train_index, test_index in kf.split(train2_X):\n",
        "    models.append(CatBoostRegressor(random_state=seed, verbose=False))\n",
        "    kfold_train_X, kfold_train_y = train2_X.iloc[train_index], train2_y.iloc[train_index]\n",
        "    kfold_test_X,  kfold_test_y  = train2_X.iloc[test_index],  train2_y.iloc[test_index]\n",
        "    train_pool = Pool(data=kfold_train_X, label=kfold_train_y, cat_features=categorical_features)\n",
        "    models[-1].fit(train_pool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "GpczmrbavgRl"
      },
      "outputs": [],
      "source": [
        "test_pool = Pool(data=test2.drop('bounced', axis=1), cat_features=categorical_features)\n",
        "pred2 = np.array(np.expm1([models[0].predict(test_pool)]))\n",
        "for i in range(1, 5):\n",
        "  pred2 = np.append(pred2, np.expm1(np.array([models[i].predict(test_pool)])),axis=0)\n",
        "pred2 = np.mean(pred2, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 예측값 후처리\n",
        "모델 1의 예측값 후처리 과정과 동일합니다."
      ],
      "metadata": {
        "id": "qLpUmwcn9ngQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred2 = [1 if i < 1 else i for i in pred2]\n",
        "for i, bounced in enumerate(test2.bounced):\n",
        "  if bounced == 'bounced':\n",
        "    pred2[i] = 1"
      ],
      "metadata": {
        "id": "nc2n3WYk1VW1"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 최종 예측값 산출 및 출력\n",
        "모델1과 모델2의 예측값의 평균을 구하고 제출 파일을 생성합니다."
      ],
      "metadata": {
        "id": "3300VtM8BQJb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "LgFfHH5ovgRm"
      },
      "outputs": [],
      "source": [
        "pred = [(p1+p2)/2 for p1,p2 in zip(pred1, pred2)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('sample_submission.csv')\n",
        "submit['TARGET'] = pred"
      ],
      "metadata": {
        "id": "udvGd6IH_Uey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "5THFGTLf_Yu3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}